# NILM Energy Monitor - Docker Compose
# Orchestrates all services for local development
#
# Usage:
#   docker compose up -d          # Start all services
#   docker compose logs -f        # View logs
#   docker compose down           # Stop all services
#   docker compose down -v        # Stop and remove volumes

services:
  # ==========================================================================
  # InfluxDB - Time Series Database
  # ==========================================================================
  influxdb:
    image: influxdb:2.8
    container_name: nilm-influxdb
    ports:
      - "8086:8086"
    volumes:
      - influxdb-data:/var/lib/influxdb2
      - influxdb-config:/etc/influxdb2
    environment:
      - DOCKER_INFLUXDB_INIT_MODE=setup
      - DOCKER_INFLUXDB_INIT_USERNAME=${INFLUX_ADMIN_USER:-admin}
      - DOCKER_INFLUXDB_INIT_PASSWORD=${INFLUX_ADMIN_PASSWORD:-admin12345}
      - DOCKER_INFLUXDB_INIT_ORG=${INFLUX_ORG:-energy-monitor}
      - DOCKER_INFLUXDB_INIT_BUCKET=${INFLUX_BUCKET_RAW:-raw_sensor_data}
      - DOCKER_INFLUXDB_INIT_ADMIN_TOKEN=${INFLUX_TOKEN}
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "influx", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ==========================================================================
  # InfluxDB Init - Create predictions bucket
  # ==========================================================================
  influxdb-init:
    image: influxdb:2.8
    container_name: nilm-influxdb-init
    depends_on:
      influxdb:
        condition: service_healthy
    environment:
      - INFLUX_HOST=http://influxdb:8086
      - INFLUX_TOKEN=${INFLUX_TOKEN}
      - INFLUX_ORG=${INFLUX_ORG:-energy-monitor}
    entrypoint: ["/bin/sh", "-c"]
    command:
      - |
        echo "Creating predictions bucket..."
        influx bucket create \
          --host $$INFLUX_HOST \
          --token $$INFLUX_TOKEN \
          --org $$INFLUX_ORG \
          --name predictions \
          --retention 0 || echo "Bucket may already exist"
        echo "InfluxDB initialization complete"
    restart: "no"

  # ==========================================================================
  # Unified Backend - Python FastAPI (replaces inference-service + local-server)
  # ==========================================================================
  backend:
    build:
      context: ./apps/backend
      dockerfile: Dockerfile
    container_name: nilm-backend
    ports:
      - "8000:8000"
    volumes:
      - ./apps/backend/models:/app/models:ro
    environment:
      - ENV=dev
      - PORT=8000
      - INFLUX_URL=http://influxdb:8086
      - INFLUX_TOKEN=${INFLUX_TOKEN}
      - INFLUX_ORG=${INFLUX_ORG:-energy-monitor}
      - INFLUX_BUCKET_RAW=${INFLUX_BUCKET_RAW:-raw_sensor_data}
      - INFLUX_BUCKET_PRED=${INFLUX_BUCKET_PRED:-predictions}
      - SUPABASE_URL=${SUPABASE_URL}
      - SUPABASE_ANON_KEY=${SUPABASE_ANON_KEY}
      - SUPABASE_JWT_SECRET=${SUPABASE_JWT_SECRET}
      - CORS_ORIGINS=http://localhost:3000,http://localhost:8080,http://localhost:5173
    depends_on:
      influxdb:
        condition: service_healthy
      influxdb-init:
        condition: service_completed_successfully
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/live"]
      interval: 10s
      timeout: 5s
      retries: 3

  # ==========================================================================
  # Legacy Inference Service (DEPRECATED - kept for migration testing)
  # ==========================================================================
  # inference-service:
  #   build:
  #     context: ./apps/inference-service
  #     dockerfile: Dockerfile
  #   container_name: nilm-inference
  #   ports:
  #     - "8001:8000"
  #   volumes:
  #     - ./models:/app/models:ro
  #   environment:
  #     - MODEL_REGISTRY_PATH=/app/model_registry.json
  #   restart: unless-stopped

volumes:
  influxdb-data:
  influxdb-config:

networks:
  default:
    name: nilm-network
