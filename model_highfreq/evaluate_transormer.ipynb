{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788afe15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model for: Dishwasher\n",
      "Model Path: transformer_10sec_dishwasher_best.pth\n",
      "Device: cuda\n",
      "Data Path found: ..\\.tmp\\10sec\\10sec\\nilm_10sec_mar_may.parquet\n",
      "Model and scalers loaded successfully.\n",
      "\n",
      "Loading dataset...\n",
      "Test samples: 95529\n",
      "\n",
      "Starting evaluation...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import mean_absolute_error, f1_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "# For PyTorch 2.6+ to allow loading Sklearn Scalers\n",
    "try:\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    torch.serialization.add_safe_globals([StandardScaler])\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    from train_transformer_10sec import NILMTransformer, Config, load_data, NILMDataset10Sec\n",
    "except ImportError:\n",
    "    from model_highfreq.train_transformer_10sec import NILMTransformer, Config, load_data, NILMDataset10Sec\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. SETUP & CONFIGURATION\n",
    "# ==============================================================================\n",
    "APPLIANCE = 'Dishwasher'\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "THRESHOLD = 0.02 # 20W detection (assuming data is in kW)\n",
    "\n",
    "# Try different possible locations for the model\n",
    "poss_model_paths = [\n",
    "    Path(f'models/transformer_10sec_{APPLIANCE.lower()}_best.pth'),\n",
    "    Path(f'../models/transformer_10sec_{APPLIANCE.lower()}_best.pth'),\n",
    "    Path(f'transformer_10sec_{APPLIANCE.lower()}_best.pth'),\n",
    "    Path(f'./transformer_10sec_{APPLIANCE.lower()}_best.pth'),\n",
    "    Path(f'model_highfreq/transformer_10sec_{APPLIANCE.lower()}_best.pth')\n",
    "]\n",
    "MODEL_FILE = next((p for p in poss_model_paths if p.exists()), None)\n",
    "\n",
    "if not MODEL_FILE:\n",
    "    from glob import glob\n",
    "    matches = glob(f'**/transformer_10sec_{APPLIANCE.lower()}_best.pth', recursive=True)\n",
    "    if matches: MODEL_FILE = Path(matches[0])\n",
    "\n",
    "print(f\"Loading model for: {APPLIANCE}\")\n",
    "print(f\"Model Path: {MODEL_FILE}\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "\n",
    "cfg = Config()\n",
    "\n",
    "# Robust Data Path Discovery\n",
    "data_possibilities = [\n",
    "    Path(cfg.DATA_PATH),\n",
    "    Path('../') / cfg.DATA_PATH,\n",
    "    Path('../../') / cfg.DATA_PATH,\n",
    "    Path(r'C:\\Users\\Tommaso\\Documents\\MEGAR2D2\\HOWEST\\TeamProject\\MTS3-MCTE-Team-Project-Energy-G1\\.tmp\\10sec\\10sec\\nilm_10sec_mar_may.parquet')\n",
    "]\n",
    "REAL_DATA_PATH = next((p for p in data_possibilities if p.exists()), None)\n",
    "print(f\"Data Path found: {REAL_DATA_PATH}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. LOAD MODEL & SCALERS\n",
    "# ==============================================================================\n",
    "if MODEL_FILE:\n",
    "    checkpoint = torch.load(MODEL_FILE, map_location=DEVICE, weights_only=False)\n",
    "    scaler_X = checkpoint['scaler_X']\n",
    "    scaler_y = checkpoint['scaler_y']\n",
    "    model = NILMTransformer(n_features=4, window_size=cfg.WINDOW_SIZE).to(DEVICE)\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    model.eval()\n",
    "    print(\"Model and scalers loaded successfully.\")\n",
    "else:\n",
    "    print(\"ERROR: Model file not found!\")\n",
    "    sys.exit()\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. LOAD DATA\n",
    "# ==============================================================================\n",
    "print(\"\\nLoading dataset...\")\n",
    "# Using a more direct reading method to bypass pandas-pyarrow re-registration issues if possible\n",
    "import pyarrow.parquet as pq\n",
    "table = pq.read_table(str(REAL_DATA_PATH))\n",
    "df = table.to_pandas()\n",
    "\n",
    "# Feature engineering\n",
    "agg = df['Aggregate'].values\n",
    "dP_dt = np.zeros_like(agg)\n",
    "dP_dt[1:] = agg[1:] - agg[:-1]\n",
    "dt = pd.to_datetime(df['Time'])\n",
    "hour = dt.dt.hour.values\n",
    "hour_sin = np.sin(2 * np.pi * hour / 24)\n",
    "hour_cos = np.cos(2 * np.pi * hour / 24)\n",
    "X_raw = np.column_stack([agg, dP_dt, hour_sin, hour_cos])\n",
    "y_raw = df[APPLIANCE].values\n",
    "\n",
    "agg_raw = X_raw[:, 0]\n",
    "X_scaled = scaler_X.transform(X_raw)\n",
    "y_scaled = scaler_y.transform(y_raw.reshape(-1, 1)).flatten()\n",
    "\n",
    "n = len(X_scaled)\n",
    "val_end = int(n * 0.85)\n",
    "\n",
    "X_test = X_scaled[val_end:]\n",
    "y_test = y_scaled[val_end:]\n",
    "agg_test = agg_raw[val_end:]\n",
    "\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "\n",
    "test_ds = NILMDataset10Sec(X_test, y_test, cfg.WINDOW_SIZE)\n",
    "test_loader = DataLoader(test_ds, batch_size=cfg.BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. EVALUATION\n",
    "# ==============================================================================\n",
    "print(\"\\nStarting evaluation...\")\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_batch, y_batch in test_loader:\n",
    "        x_batch = x_batch.to(DEVICE)\n",
    "        # Use try-except to handle possible device mismatch in some kernels\n",
    "        try:\n",
    "            outputs = model(x_batch).squeeze().cpu().numpy()\n",
    "        except:\n",
    "             outputs = model(x_batch.to(DEVICE)).squeeze().cpu().numpy()\n",
    "        all_preds.append(outputs)\n",
    "        all_targets.append(y_batch.numpy())\n",
    "\n",
    "y_pred_scaled = np.concatenate(all_preds).reshape(-1, 1)\n",
    "y_true_scaled = np.concatenate(all_targets).reshape(-1, 1)\n",
    "\n",
    "y_pred_real = np.maximum(scaler_y.inverse_transform(y_pred_scaled).flatten(), 0)\n",
    "y_true_real = scaler_y.inverse_transform(y_true_scaled).flatten()\n",
    "\n",
    "mid = cfg.WINDOW_SIZE // 2\n",
    "agg_vis = agg_test[mid : mid + len(y_pred_real)]\n",
    "y_true_vis = y_true_real\n",
    "\n",
    "y_pred_bin = (y_pred_real > THRESHOLD).astype(int)\n",
    "y_true_bin = (y_true_vis > THRESHOLD).astype(int)\n",
    "\n",
    "f1 = f1_score(y_true_bin, y_pred_bin, zero_division=0)\n",
    "mae = mean_absolute_error(y_true_vis, y_pred_real)\n",
    "\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(f\"RESULTS FOR {APPLIANCE}\")\n",
    "print(f\"MAE: {mae*1000:.2f} W\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. VISUALIZATION\n",
    "# ==============================================================================\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "# Plot 1: Overview\n",
    "ax1.plot(agg_vis[:10000], label='Aggregate (Total House)', color='black', alpha=0.15)\n",
    "ax1.plot(y_true_vis[:10000], label='Ground Truth', color='C0', alpha=0.8)\n",
    "ax1.plot(y_pred_real[:10000], label='Transformer Prediction', color='C1', alpha=0.7)\n",
    "ax1.set_title(f'{APPLIANCE} Overview - Test Set')\n",
    "ax1.set_ylabel('Power (kW)')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.2)\n",
    "\n",
    "# Plot 2: Zoom on first active cycle found\n",
    "on_indices = np.where(y_true_vis > THRESHOLD)[0]\n",
    "if len(on_indices) > 0:\n",
    "    idx = on_indices[0] + 500 # Just taking a window near the start\n",
    "    start, end = max(0, idx - 500), min(len(y_true_vis), idx + 1500)\n",
    "    \n",
    "    ax2.fill_between(range(end-start), 0, agg_vis[start:end], color='black', alpha=0.05, label='Aggregate')\n",
    "    ax2.plot(y_true_vis[start:end], label='Ground Truth', color='C0', linewidth=2)\n",
    "    ax2.plot(y_pred_real[start:end], label='Transformer', color='C1', linestyle='--', linewidth=2)\n",
    "    ax2.set_title(f'{APPLIANCE} - Active Sequence Comparison')\n",
    "    ax2.set_ylabel('Power (kW)')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
