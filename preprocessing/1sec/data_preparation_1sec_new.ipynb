{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b791551b",
   "metadata": {},
   "source": [
    "# Data Preparation for New 1-Second Data (1sec_new)\n",
    "---\n",
    "\n",
    "This notebook preprocesses the **new 1-second resolution data** from the `1sec_new` folder.\n",
    "\n",
    "## Why Keep 1-Second Resolution?\n",
    "According to NILM literature, **1 second is significantly better than 10 seconds** for Transformer-based NILM:\n",
    "- Better accuracy for short-cycle appliances (kettles, microwaves)\n",
    "- Standard resolution for state-of-the-art models (ELECTRIcity, Energformer, STNILM)\n",
    "- Preserves transient events that get \"smoothed out\" at lower resolutions\n",
    "\n",
    "## Data Overview\n",
    "- **21 months raw** (March 2024 - December 2025)\n",
    "- **494 days usable** after filtering to gap-free periods\n",
    "- **~40M rows** at 1-second resolution\n",
    "\n",
    "## Usable Periods (Gap-Free)\n",
    "| Period | Start | End | Days |\n",
    "|--------|-------|-----|------|\n",
    "| A | 2024-04-15 | 2024-05-31 | 46 |\n",
    "| B | 2024-07-01 | 2024-09-30 | 92 |\n",
    "| C | 2024-10-09 | 2025-09-30 | 356 |\n",
    "\n",
    "## Key Processing Steps (Based on EDA Analysis - see eda_1sec_new.ipynb):\n",
    "1. **clip(lower=0) for ALL appliances**: dishwasher, washing_machine, stove, oven, etc.\n",
    "   - EDA shows: 85-99% negative but values are SMALL (-8W to -15W)\n",
    "   - Positives are LARGE (1000-3600W) when ON\n",
    "   - This is **SENSOR OFFSET**, NOT inverted CT!\n",
    "   - If inverted CT: we'd see LARGE negatives when ON\n",
    "2. **Fix double counting**: `garage_cabinet -= ev_charger + ev_socket`\n",
    "   - Confirmed via analysis: garage >= EV 100% of time\n",
    "3. **Noise thresholding**: Values < 5W \u2192 0\n",
    "   - Clean \"OFF\" states for model training\n",
    "4. Keep negative values for Solar, Grid, Battery (bidirectional energy flow)\n",
    "5. Fill EVCharger/EVSocket with 0 before Aug 2024\n",
    "6. **NO resampling - keep native 1sec resolution**\n",
    "7. Add cyclical temporal features\n",
    "\n",
    "## Corrections Rationale (Validated via eda_1sec_new.ipynb):\n",
    "| Issue | Columns Affected | Solution | Evidence |\n",
    "|-------|-----------------|----------|----------|\n",
    "| **OFFSET (NOT inverted CT!)** | dishwasher, washing_machine, stove | `clip(0)` | Neg: -8 to -15W, Pos: 1000-3600W |\n",
    "| Sensor noise | dryer, heat_pump, range_hood, etc. | `clip(0)` | <5% negative, small magnitude |\n",
    "| Double counting | garage_cabinet | Subtract EV | garage >= EV 100% of time |\n",
    "| Small positive noise | All appliances | Threshold < 5W \u2192 0 | Dryer shows 3W when OFF |\n",
    "\n",
    "**IMPORTANT**: abs() is WRONG for this data because:\n",
    "- Negative values are TINY (-8W to -15W) = sensor offset when OFF\n",
    "- Positive values are LARGE (1000W+) = real consumption when ON\n",
    "- abs() would flip tiny offsets to tiny positives (no meaningful change)\n",
    "- clip(0) correctly zeros out the small offsets\n",
    "\n",
    "## Output:\n",
    "- NILM-ready dataset at **1-second resolution** (~40M rows)\n",
    "- Consistent feature set: 11 appliances + Solar/Grid + 6 temporal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73d9ea9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base directory: C:\\Users\\gamek\\School\\TeamProject\\MTS3-MCTE-Team-Project-Energy-G1\n",
      "Raw data: C:\\Users\\gamek\\School\\TeamProject\\MTS3-MCTE-Team-Project-Energy-G1\\data\\raw\\1sec_new\n",
      "Output: C:\\Users\\gamek\\School\\TeamProject\\MTS3-MCTE-Team-Project-Energy-G1\\data\\processed\\1sec_processed\n",
      "\n",
      "Files available:\n",
      "   household_2024_03.csv\n",
      "   household_2024_04.csv\n",
      "   household_2024_05.csv\n",
      "   household_2024_07.csv\n",
      "   household_2024_08.csv\n",
      "   household_2024_09.csv\n",
      "   household_2024_10.csv\n",
      "   household_2024_11.csv\n",
      "   household_2024_12.csv\n",
      "   household_2025_01.csv\n",
      "   household_2025_02.csv\n",
      "   household_2025_03.csv\n",
      "   household_2025_04.csv\n",
      "   household_2025_05.csv\n",
      "   household_2025_06.csv\n",
      "   household_2025_07.csv\n",
      "   household_2025_08.csv\n",
      "   household_2025_09.csv\n",
      "   household_2025_10.csv\n",
      "   household_2025_11.csv\n",
      "   household_2025_12.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Paths - OUTPUT IS 1sec (NO resampling!)\n",
    "BASE_DIR = Path('.').resolve().parent.parent\n",
    "RAW_DIR = BASE_DIR / 'data' / 'raw' / '1sec_new'\n",
    "OUTPUT_DIR = BASE_DIR / 'data' / 'processed' / '1sec_processed'\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f'Base directory: {BASE_DIR}')\n",
    "print(f'Raw data: {RAW_DIR}')\n",
    "print(f'Output: {OUTPUT_DIR}')\n",
    "print(f'\\nFiles available:')\n",
    "for f in sorted(RAW_DIR.glob('*.csv')):\n",
    "    print(f'   {f.name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b92b05",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Define Target Columns & Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d291ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target columns defined.\n",
      "\n",
      "\ud83d\udccb Correction Strategy:\n",
      "   1. clip(lower=0) for ALL appliances (offset removal, NOT abs!)\n",
      "   2. Noise threshold: 5W (values below \u2192 0)\n",
      "   3. Double counting fix: garage_cabinet -= ['ev_charger', 'ev_socket']\n",
      "   4. Keep negatives: ['solar', 'grid', 'battery']\n"
     ]
    }
   ],
   "source": [
    "# Standard column set for output\n",
    "# Using lowercase with underscores to match new data format\n",
    "\n",
    "TARGET_COLUMNS = {\n",
    "    'time': 'Time',\n",
    "    \n",
    "    # Aggregate columns - pick the main building\n",
    "    'building_33a8340b-f03c-4851-9f9f-99b98e2c4cc9': 'Aggregate',\n",
    "    'building_33a8340b-f03c-4851-9f9f-99b98e2c4cc12': 'Aggregate',  # Older files\n",
    "    \n",
    "    # Appliances\n",
    "    'heat_pump': 'HeatPump',\n",
    "    'dishwasher': 'Dishwasher',\n",
    "    'washing_machine': 'WashingMachine',\n",
    "    'dryer': 'Dryer',\n",
    "    'oven': 'Oven',\n",
    "    'stove': 'Stove',\n",
    "    'range_hood': 'RangeHood',\n",
    "    'ev_charger': 'EVCharger',\n",
    "    'ev_socket': 'EVSocket',\n",
    "    'garage_cabinet': 'GarageCabinet',\n",
    "    'rainwater_pump': 'RainwaterPump',\n",
    "    \n",
    "    # Solar & Grid (keep signs for energy flow analysis)\n",
    "    'solar': 'Solar',\n",
    "    'grid': 'Grid',\n",
    "    \n",
    "    # Battery (only in late 2025)\n",
    "    'battery': 'Battery'\n",
    "}\n",
    "\n",
    "# =============================================================================\n",
    "# CORRECTION SETTINGS \n",
    "# Based on raw data analysis (see temp/analyze_raw_1sec.py)\n",
    "# =============================================================================\n",
    "\n",
    "# Columns where negative is meaningful (bidirectional energy flow)\n",
    "ALLOW_NEGATIVE = ['solar', 'grid', 'battery', \n",
    "                  'building_33a8340b-f03c-4851-9f9f-99b98e2c4cc9',\n",
    "                  'building_33a8340b-f03c-4851-9f9f-99b98e2c4cc12']\n",
    "\n",
    "# =============================================================================\n",
    "# NOTE: NO abs() needed!\n",
    "# EDA analysis (eda_1sec_new.ipynb) shows:\n",
    "# - dishwasher, washing_machine, stove have 85-99% negative values\n",
    "# - BUT: negatives are SMALL (-8W to -15W) = sensor offset when OFF\n",
    "# - AND: positives are LARGE (1000-3600W) = real consumption when ON\n",
    "# - This is OFFSET, NOT inverted CT!\n",
    "# - If inverted CT: we'd see LARGE negatives (-2000W) when ON\n",
    "# - Solution: clip(lower=0), NOT abs()\n",
    "# =============================================================================\n",
    "\n",
    "# Noise threshold: Values below this are sensor noise (set to 0)\n",
    "# Applied AFTER clip(0) correction\n",
    "# Reason: Some appliances show ~3W offset even when OFF\n",
    "NOISE_THRESHOLD_KW = 0.005  # 5 Watts\n",
    "\n",
    "# Double counting hierarchy (same as 15-min: Kast garage contains EV chargers)\n",
    "# garage_cabinet = garage_cabinet - ev_charger - ev_socket\n",
    "DOUBLE_COUNTING_PARENT = 'garage_cabinet'\n",
    "DOUBLE_COUNTING_CHILDREN = ['ev_charger', 'ev_socket']\n",
    "\n",
    "print('Target columns defined.')\n",
    "print(f'\\n\ud83d\udccb Correction Strategy:')\n",
    "print(f'   1. clip(lower=0) for ALL appliances (offset removal, NOT abs!)')\n",
    "print(f'   2. Noise threshold: {NOISE_THRESHOLD_KW*1000:.0f}W (values below \u2192 0)')\n",
    "print(f'   3. Double counting fix: {DOUBLE_COUNTING_PARENT} -= {DOUBLE_COUNTING_CHILDREN}')\n",
    "print(f'   4. Keep negatives: {[c for c in ALLOW_NEGATIVE if \"building\" not in c]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f42528",
   "metadata": {},
   "source": [
    "---\n",
    "## 1b. Define Usable Periods (Gap-Free)\n",
    "Based on detailed exploration of 1sec_new data, we identified 3 continuous periods without gaps.\n",
    "These periods have all essential columns present with no Building NULL values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc9f2f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "\ud83d\udcc5 USABLE PERIODS DEFINED\n",
      "======================================================================\n",
      "Period A: 2024-04-15 00:00:00 \u2192 2024-05-31 23:59:59\n",
      "Period B: 2024-07-01 00:00:00 \u2192 2024-09-30 23:59:59\n",
      "Period C: 2024-10-09 12:15:00 \u2192 2025-09-30 23:59:59\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# USABLE PERIODS (from gap analysis)\n",
    "# =============================================================================\n",
    "# These are continuous periods WITHOUT gaps (max 10 min allowed)\n",
    "# Identified via deep_explore_v2.py and find_continuous_periods.py\n",
    "\n",
    "USABLE_PERIODS = [\n",
    "    # Period A: April-May 2024 (partial)\n",
    "    # 46 days, ~1.2M rows - some early gaps excluded\n",
    "    ('2024-04-15 00:00:00', '2024-05-31 23:59:59'),\n",
    "    \n",
    "    # Period B: July-September 2024\n",
    "    # 92 days, ~7.9M rows - June 2024 completely missing\n",
    "    ('2024-07-01 00:00:00', '2024-09-30 23:59:59'),\n",
    "    \n",
    "    # Period C: October 2024 - September 2025\n",
    "    # 356 days, ~30.8M rows - MAIN PERIOD\n",
    "    # Starts from Oct 9 due to early October gap\n",
    "    ('2024-10-09 12:15:00', '2025-09-30 23:59:59'),\n",
    "]\n",
    "\n",
    "# Note: October-December 2025 have gaps and should NOT be used\n",
    "# Battery column (Nov-Dec 2025 only) is also excluded for consistency\n",
    "\n",
    "print('='*70)\n",
    "print('\ud83d\udcc5 USABLE PERIODS DEFINED')\n",
    "print('='*70)\n",
    "for i, (start, end) in enumerate(USABLE_PERIODS):\n",
    "    print(f'Period {chr(65+i)}: {start} \u2192 {end}')\n",
    "print('='*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02341869",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Load and Process All Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2108cb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested on: household_2024_03.csv\n",
      "Result columns: ['Time', 'Aggregate', 'HeatPump', 'Dishwasher', 'WashingMachine', 'Dryer', 'Oven', 'Stove', 'RangeHood', 'EVCharger', 'EVSocket', 'GarageCabinet', 'RainwaterPump', 'Solar', 'Grid', 'Battery']\n",
      "Rows: 154,236\n",
      "\n",
      "\u2705 Corrections Applied:\n",
      "   1. clip(0) for ALL appliances (offset removal, NOT abs!)\n",
      "   2. Double counting: GarageCabinet -= EVCharger + EVSocket\n",
      "   3. Noise threshold: values < 5W \u2192 0\n"
     ]
    }
   ],
   "source": [
    "def process_single_file(filepath):\n",
    "    \"\"\"Process a single CSV file with all necessary corrections.\n",
    "    \n",
    "    Corrections applied (based on EDA analysis - eda_1sec_new.ipynb):\n",
    "    1. clip(lower=0) for ALL appliance columns\n",
    "       - Negative values are SMALL sensor offsets (-8W to -15W)\n",
    "       - NOT inverted CT (which would show LARGE negatives when ON)\n",
    "    2. Fix double counting: garage_cabinet -= ev_charger + ev_socket\n",
    "    3. Apply noise threshold: values < 5W \u2192 0 (sensor noise when OFF)\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    # 1. Parse timestamp\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "    \n",
    "    # 2. Clip ALL appliance negatives to 0\n",
    "    # EDA shows: negatives are SMALL offsets (-8W to -15W)\n",
    "    # Positives are LARGE when ON (1000W+) \u2192 this is OFFSET, not inverted CT\n",
    "    for col in df.columns:\n",
    "        if col not in ALLOW_NEGATIVE and col != 'time':\n",
    "            if df[col].dtype in ['float64', 'int64']:\n",
    "                df[col] = df[col].clip(lower=0)\n",
    "    \n",
    "    # 3. Fix double counting: garage_cabinet contains EV chargers\n",
    "    # Same logic as 15-min: Kast garage -= Smappee_laadpaal + Laadpaal_stopcontact\n",
    "    if DOUBLE_COUNTING_PARENT in df.columns:\n",
    "        subtraction = 0\n",
    "        for child in DOUBLE_COUNTING_CHILDREN:\n",
    "            if child in df.columns:\n",
    "                subtraction = subtraction + df[child]\n",
    "        df[DOUBLE_COUNTING_PARENT] = (df[DOUBLE_COUNTING_PARENT] - subtraction).clip(lower=0)\n",
    "    \n",
    "    # 4. Apply noise threshold: small positive values \u2192 0\n",
    "    # Reason: Some appliances show ~3W offset when OFF\n",
    "    for col in df.columns:\n",
    "        if col not in ALLOW_NEGATIVE and col != 'time' and df[col].dtype in ['float64', 'int64']:\n",
    "            mask = (df[col] > 0) & (df[col] < NOISE_THRESHOLD_KW)\n",
    "            df.loc[mask, col] = 0\n",
    "    \n",
    "    # 6. Handle missing columns - find aggregate column\n",
    "    agg_col = None\n",
    "    for col in ['building_33a8340b-f03c-4851-9f9f-99b98e2c4cc9', \n",
    "                'building_33a8340b-f03c-4851-9f9f-99b98e2c4cc12']:\n",
    "        if col in df.columns:\n",
    "            agg_col = col\n",
    "            break\n",
    "    \n",
    "    if agg_col is None:\n",
    "        print(f\"WARNING: No aggregate column found in {filepath.name}\")\n",
    "        return None\n",
    "    \n",
    "    # 7. Create standardized dataframe\n",
    "    result = pd.DataFrame()\n",
    "    result['Time'] = df['time']\n",
    "    result['Aggregate'] = df[agg_col].clip(lower=0)  # Clip negatives (CT noise)\n",
    "    \n",
    "    # Add appliances\n",
    "    appliance_cols = ['heat_pump', 'dishwasher', 'washing_machine', 'dryer',\n",
    "                     'oven', 'stove', 'range_hood', 'ev_charger', 'ev_socket',\n",
    "                     'garage_cabinet', 'rainwater_pump']\n",
    "    \n",
    "    for col in appliance_cols:\n",
    "        if col in df.columns:\n",
    "            result[TARGET_COLUMNS.get(col, col)] = df[col]\n",
    "        else:\n",
    "            result[TARGET_COLUMNS.get(col, col)] = 0.0  # Fill missing with zeros\n",
    "    \n",
    "    # Add solar, grid, battery (keep signs for energy flow)\n",
    "    if 'solar' in df.columns:\n",
    "        result['Solar'] = df['solar']\n",
    "    if 'grid' in df.columns:\n",
    "        result['Grid'] = df['grid']\n",
    "    if 'battery' in df.columns:\n",
    "        result['Battery'] = df['battery']\n",
    "    else:\n",
    "        result['Battery'] = 0.0\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test on first file\n",
    "test_file = sorted(RAW_DIR.glob('*.csv'))[0]\n",
    "test_df = process_single_file(test_file)\n",
    "print(f'Tested on: {test_file.name}')\n",
    "print(f'Result columns: {list(test_df.columns)}')\n",
    "print(f'Rows: {len(test_df):,}')\n",
    "\n",
    "# Verify corrections\n",
    "print(f'\\n\u2705 Corrections Applied:')\n",
    "print(f'   1. clip(0) for ALL appliances (offset removal, NOT abs!)')\n",
    "print(f'   2. Double counting: GarageCabinet -= EVCharger + EVSocket')\n",
    "print(f'   3. Noise threshold: values < {NOISE_THRESHOLD_KW*1000:.0f}W \u2192 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4a80c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "\ud83d\udcc2 LOADING ALL FILES\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   5%|\u258d         | 1/21 [00:00<00:07,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \u2705 household_2024_03.csv: 154,236 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  10%|\u2589         | 2/21 [00:00<00:09,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \u2705 household_2024_04.csv: 218,821 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  14%|\u2588\u258d        | 3/21 [00:03<00:29,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \u2705 household_2024_05.csv: 1,080,770 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  19%|\u2588\u2589        | 4/21 [00:24<02:31,  8.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \u2705 household_2024_07.csv: 2,673,691 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  24%|\u2588\u2588\u258d       | 5/21 [00:38<02:54, 10.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \u2705 household_2024_08.csv: 2,677,885 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  29%|\u2588\u2588\u258a       | 6/21 [00:44<02:16,  9.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \u2705 household_2024_09.csv: 2,590,681 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  33%|\u2588\u2588\u2588\u258e      | 7/21 [00:50<01:53,  8.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \u2705 household_2024_10.csv: 2,046,755 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  38%|\u2588\u2588\u2588\u258a      | 8/21 [00:57<01:43,  7.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \u2705 household_2024_11.csv: 2,589,684 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  43%|\u2588\u2588\u2588\u2588\u258e     | 9/21 [01:05<01:35,  7.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \u2705 household_2024_12.csv: 2,675,505 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  48%|\u2588\u2588\u2588\u2588\u258a     | 10/21 [01:13<01:25,  7.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \u2705 household_2025_01.csv: 2,673,103 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 11/21 [01:18<01:10,  7.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \u2705 household_2025_02.csv: 2,419,200 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 12/21 [01:25<01:04,  7.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \u2705 household_2025_03.csv: 2,678,348 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 13/21 [01:33<00:58,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \u2705 household_2025_04.csv: 2,581,542 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 14/21 [01:41<00:51,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \u2705 household_2025_05.csv: 2,676,913 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 15/21 [01:49<00:46,  7.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \u2705 household_2025_06.csv: 2,591,220 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 16/21 [01:58<00:39,  8.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \u2705 household_2025_07.csv: 2,678,081 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 17/21 [02:05<00:30,  7.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \u2705 household_2025_08.csv: 2,672,659 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 18/21 [02:12<00:22,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \u2705 household_2025_09.csv: 2,590,780 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 19/21 [02:19<00:14,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \u2705 household_2025_10.csv: 2,463,145 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 20/21 [02:28<00:07,  7.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \u2705 household_2025_11.csv: 2,496,891 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 21/21 [02:32<00:00,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \u2705 household_2025_12.csv: 1,412,067 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Process all files\n",
    "print('='*70)\n",
    "print('\ud83d\udcc2 LOADING ALL FILES')\n",
    "print('='*70)\n",
    "\n",
    "all_files = sorted(RAW_DIR.glob('*.csv'))\n",
    "dfs = []\n",
    "\n",
    "for f in tqdm(all_files, desc='Processing'):\n",
    "    df_file = process_single_file(f)\n",
    "    if df_file is not None:\n",
    "        dfs.append(df_file)\n",
    "        print(f'   \u2705 {f.name}: {len(df_file):,} rows')\n",
    "\n",
    "# Combine\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "df = df.sort_values('Time').reset_index(drop=True)\n",
    "\n",
    "print(f'\\n\ud83d\udcca Combined (all): {len(df):,} rows')\n",
    "print(f'   Time: {df[\"Time\"].min()} \u2192 {df[\"Time\"].max()}')\n",
    "\n",
    "# =============================================================================\n",
    "# FILTER TO USABLE PERIODS ONLY\n",
    "# =============================================================================\n",
    "print(f'\\n\ud83d\udd27 FILTERING TO USABLE PERIODS...')\n",
    "rows_before = len(df)\n",
    "\n",
    "# Create mask for usable periods\n",
    "period_mask = pd.Series([False] * len(df), index=df.index)\n",
    "\n",
    "for i, (start, end) in enumerate(USABLE_PERIODS):\n",
    "    start_dt = pd.to_datetime(start)\n",
    "    end_dt = pd.to_datetime(end)\n",
    "    mask_i = (df['Time'] >= start_dt) & (df['Time'] <= end_dt)\n",
    "    rows_in_period = mask_i.sum()\n",
    "    period_mask = period_mask | mask_i\n",
    "    print(f'   Period {chr(65+i)}: {start} \u2192 {end}')\n",
    "    print(f'           {rows_in_period:,} rows ({rows_in_period/rows_before*100:.1f}%)')\n",
    "\n",
    "# Apply filter\n",
    "df = df[period_mask].reset_index(drop=True)\n",
    "rows_after = len(df)\n",
    "\n",
    "print(f'\\n\ud83d\udcca After filtering:')\n",
    "print(f'   Rows: {rows_before:,} \u2192 {rows_after:,}')\n",
    "print(f'   Removed: {rows_before - rows_after:,} rows ({(rows_before - rows_after)/rows_before*100:.1f}%)')\n",
    "print(f'   Time: {df[\"Time\"].min()} \u2192 {df[\"Time\"].max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c4e6a7",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Data Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efed8375",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*70)\n",
    "print('\ud83d\udd0d DATA QUALITY CHECK')\n",
    "print('='*70)\n",
    "\n",
    "# Check for nulls\n",
    "null_counts = df.isna().sum()\n",
    "print(f'\\nNull values:')\n",
    "for col in df.columns:\n",
    "    if null_counts[col] > 0:\n",
    "        print(f'   {col}: {null_counts[col]:,} ({null_counts[col]/len(df)*100:.2f}%)')\n",
    "\n",
    "if null_counts.sum() == 0:\n",
    "    print('   \u2705 No null values!')\n",
    "\n",
    "# Check for remaining negatives in appliances\n",
    "print(f'\\nNegative value check (appliances):')\n",
    "appliance_cols = ['HeatPump', 'Dishwasher', 'WashingMachine', 'Dryer', 'Oven', \n",
    "                  'Stove', 'RangeHood', 'EVCharger', 'EVSocket', 'GarageCabinet', 'RainwaterPump']\n",
    "for col in appliance_cols:\n",
    "    if col in df.columns:\n",
    "        neg_count = (df[col] < 0).sum()\n",
    "        if neg_count > 0:\n",
    "            print(f'   \u26a0\ufe0f {col}: {neg_count:,} negative values')\n",
    "\n",
    "# Show statistics\n",
    "print(f'\\n\ud83d\udcca Column Statistics:')\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "stats_df = df[numeric_cols].describe().round(4)\n",
    "print(stats_df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f02d54",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Verify 1-Second Resolution (NO Resampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14288f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*70)\n",
    "print('\u23f1\ufe0f VERIFYING 1-SECOND RESOLUTION (NO RESAMPLING)')\n",
    "print('='*70)\n",
    "\n",
    "# Check current resolution\n",
    "time_diffs = df['Time'].diff().dt.total_seconds().dropna()\n",
    "print(f'\\nResolution distribution:')\n",
    "for diff, count in time_diffs.value_counts().head(5).items():\n",
    "    print(f'   {diff:.0f}sec: {count:,} ({count/len(time_diffs)*100:.1f}%)')\n",
    "\n",
    "# Verify mostly 1-second\n",
    "pct_1sec = (time_diffs == 1).sum() / len(time_diffs) * 100\n",
    "print(f'\\n\u2705 {pct_1sec:.1f}% of data is at 1-second resolution')\n",
    "print(f'   Total rows: {len(df):,}')\n",
    "print(f'\\n\ud83d\udccc KEEPING NATIVE 1-SECOND RESOLUTION FOR BEST NILM ACCURACY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53113ed0",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Final Negative Value Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7262c952",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*70)\n",
    "print('\u2702\ufe0f FINAL CLEANUP: Clipping Small Negatives')\n",
    "print('='*70)\n",
    "\n",
    "# For appliances: clip to 0\n",
    "appliance_cols = ['HeatPump', 'Dishwasher', 'WashingMachine', 'Dryer', 'Oven', \n",
    "                  'Stove', 'RangeHood', 'EVCharger', 'EVSocket', 'GarageCabinet', \n",
    "                  'RainwaterPump', 'Aggregate']\n",
    "\n",
    "print('\\nNegative values before clipping:')\n",
    "for col in appliance_cols:\n",
    "    if col in df.columns:\n",
    "        neg_count = (df[col] < 0).sum()\n",
    "        if neg_count > 0:\n",
    "            neg_pct = neg_count / len(df) * 100\n",
    "            print(f'   {col}: {neg_count:,} ({neg_pct:.1f}%)')\n",
    "            df[col] = df[col].clip(lower=0)\n",
    "\n",
    "# For Solar/Grid/Battery: keep negative values (meaningful)\n",
    "print(f'\\n\u2705 Solar, Grid, Battery: keeping negative values (energy flow)')\n",
    "\n",
    "print('\\n\u2705 Cleanup complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9ff862",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Time Gap Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48f2988",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*70)\n",
    "print('\ud83d\udd73\ufe0f TIME GAP ANALYSIS')\n",
    "print('='*70)\n",
    "\n",
    "df['Time'] = pd.to_datetime(df['Time'])\n",
    "time_diffs = df['Time'].diff().dt.total_seconds()\n",
    "\n",
    "# Analyze gaps\n",
    "gaps_1min = (time_diffs > 60).sum()\n",
    "gaps_1hour = (time_diffs > 3600).sum()\n",
    "max_gap = time_diffs.max()\n",
    "\n",
    "print(f'\\nTotal rows: {len(df):,}')\n",
    "print(f'Gaps > 1 minute: {gaps_1min:,}')\n",
    "print(f'Gaps > 1 hour: {gaps_1hour:,}')\n",
    "print(f'Max gap: {max_gap/3600:.2f} hours')\n",
    "\n",
    "if gaps_1hour > 0:\n",
    "    print(f'\\nLarge gaps (> 1 hour):')\n",
    "    large_gaps = time_diffs[time_diffs > 3600]\n",
    "    for idx in large_gaps.index[:10]:\n",
    "        gap_h = time_diffs.loc[idx] / 3600\n",
    "        gap_time = df.loc[idx-1, 'Time'] if idx > 0 else 'N/A'\n",
    "        print(f'   {gap_h:.2f}h after {gap_time}')\n",
    "\n",
    "print('\\n\ud83d\udccc Note: Gaps will be handled during model training (windowing excludes gap-crossing windows)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9853ffa",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Add Temporal Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ebde6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*70)\n",
    "print('\u23f0 ADDING TEMPORAL FEATURES')\n",
    "print('='*70)\n",
    "\n",
    "# Extract time components\n",
    "df['hour'] = df['Time'].dt.hour + df['Time'].dt.minute / 60 + df['Time'].dt.second / 3600\n",
    "df['dow'] = df['Time'].dt.dayofweek  # 0=Monday\n",
    "df['month'] = df['Time'].dt.month\n",
    "\n",
    "# Cyclical encoding\n",
    "df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "\n",
    "df['dow_sin'] = np.sin(2 * np.pi * df['dow'] / 7)\n",
    "df['dow_cos'] = np.cos(2 * np.pi * df['dow'] / 7)\n",
    "\n",
    "df['month_sin'] = np.sin(2 * np.pi * (df['month'] - 1) / 12)\n",
    "df['month_cos'] = np.cos(2 * np.pi * (df['month'] - 1) / 12)\n",
    "\n",
    "# Drop intermediate columns\n",
    "df = df.drop(columns=['hour', 'dow', 'month'])\n",
    "\n",
    "print('\\nTemporal features added:')\n",
    "print('   \u2022 hour_sin, hour_cos (24h cycle)')\n",
    "print('   \u2022 dow_sin, dow_cos (7-day cycle)')\n",
    "print('   \u2022 month_sin, month_cos (12-month cycle)')\n",
    "\n",
    "print(f'\\nFinal columns ({len(df.columns)}): {list(df.columns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9f840f",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Ghost Load Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513d9bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*70)\n",
    "print('\ud83d\udc7b GHOST LOAD ANALYSIS')\n",
    "print('='*70)\n",
    "\n",
    "# Appliance columns for sum\n",
    "appliance_cols = ['HeatPump', 'Dishwasher', 'WashingMachine', 'Dryer', 'Oven', \n",
    "                  'Stove', 'RangeHood', 'EVCharger', 'EVSocket', 'GarageCabinet', 'RainwaterPump']\n",
    "existing_appliances = [c for c in appliance_cols if c in df.columns]\n",
    "\n",
    "# Calculate sum of appliances\n",
    "df['_sum_appliances'] = df[existing_appliances].sum(axis=1)\n",
    "df['_ghost_load'] = df['Aggregate'] - df['_sum_appliances']\n",
    "\n",
    "agg_mean = df['Aggregate'].mean()\n",
    "sum_mean = df['_sum_appliances'].mean()\n",
    "ghost_mean = df['_ghost_load'].mean()\n",
    "ghost_pct = ghost_mean / agg_mean * 100 if agg_mean > 0 else 0\n",
    "\n",
    "print(f'\\n\ud83d\udcca Energy Balance:')\n",
    "print(f'   Aggregate mean:      {agg_mean:.4f} kW')\n",
    "print(f'   Sum(Appliances):     {sum_mean:.4f} kW')\n",
    "print(f'   Ghost Load:          {ghost_mean:.4f} kW ({ghost_pct:.1f}%)')\n",
    "\n",
    "# Correlation\n",
    "corr = df['Aggregate'].corr(df['_sum_appliances'])\n",
    "print(f'\\n   Correlation Aggregate vs Sum: {corr:.4f}')\n",
    "\n",
    "# Analysis of exceed cases\n",
    "exceed_cases = (df['_sum_appliances'] > df['Aggregate']).sum()\n",
    "exceed_pct = exceed_cases / len(df) * 100\n",
    "print(f'\\n   Cases where Sum > Aggregate: {exceed_cases:,} ({exceed_pct:.1f}%)')\n",
    "\n",
    "# Drop temporary columns\n",
    "df = df.drop(columns=['_sum_appliances', '_ghost_load'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454a78dc",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f07441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample for visualization\n",
    "sample_size = min(10000, len(df))\n",
    "df_sample = df.sample(sample_size, random_state=42).sort_values('Time')\n",
    "\n",
    "# Recalculate sum for visualization\n",
    "appliance_cols = ['HeatPump', 'Dishwasher', 'WashingMachine', 'Dryer', 'Oven', \n",
    "                  'Stove', 'RangeHood', 'EVCharger', 'EVSocket', 'GarageCabinet', 'RainwaterPump']\n",
    "existing_appliances = [c for c in appliance_cols if c in df_sample.columns]\n",
    "df_sample['_sum'] = df_sample[existing_appliances].sum(axis=1)\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 12))\n",
    "\n",
    "# 1. Time series: Aggregate vs Sum\n",
    "ax1 = axes[0]\n",
    "ax1.plot(df_sample['Time'], df_sample['Aggregate'], alpha=0.7, label='Aggregate', linewidth=0.5)\n",
    "ax1.plot(df_sample['Time'], df_sample['_sum'], alpha=0.7, label='Sum(Appliances)', linewidth=0.5)\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Power (kW)')\n",
    "ax1.set_title('Aggregate vs Sum of Appliances (10sec resolution)')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Scatter: Aggregate vs Sum\n",
    "ax2 = axes[1]\n",
    "ax2.scatter(df_sample['_sum'], df_sample['Aggregate'], alpha=0.3, s=5)\n",
    "max_val = max(df_sample['Aggregate'].max(), df_sample['_sum'].max())\n",
    "ax2.plot([0, max_val], [0, max_val], 'r--', label='y=x (perfect match)')\n",
    "ax2.set_xlabel('Sum(Appliances) (kW)')\n",
    "ax2.set_ylabel('Aggregate (kW)')\n",
    "corr = df_sample['Aggregate'].corr(df_sample['_sum'])\n",
    "ax2.set_title(f'Correlation: {corr:.3f}')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Solar and Grid\n",
    "ax3 = axes[2]\n",
    "if 'Solar' in df_sample.columns:\n",
    "    ax3.plot(df_sample['Time'], df_sample['Solar'], alpha=0.7, label='Solar', linewidth=0.5, color='orange')\n",
    "if 'Grid' in df_sample.columns:\n",
    "    ax3.plot(df_sample['Time'], df_sample['Grid'], alpha=0.7, label='Grid', linewidth=0.5, color='blue')\n",
    "ax3.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "ax3.set_xlabel('Time')\n",
    "ax3.set_ylabel('Power (kW)')\n",
    "ax3.set_title('Solar Generation and Grid Exchange (negative = export)')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ee238b",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Final Null Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b89bf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*70)\n",
    "print('\ud83d\udd27 FINAL NULL HANDLING')\n",
    "print('='*70)\n",
    "\n",
    "# Check for nulls\n",
    "null_counts = df.isna().sum()\n",
    "total_nulls = null_counts.sum()\n",
    "\n",
    "print(f'\\nNull values before handling: {total_nulls}')\n",
    "\n",
    "if total_nulls > 0:\n",
    "    for col in df.columns:\n",
    "        if null_counts[col] > 0:\n",
    "            print(f'   {col}: {null_counts[col]:,}')\n",
    "    \n",
    "    # Forward fill for small gaps (up to 1 minute = 6 rows at 10sec)\n",
    "    df = df.fillna(method='ffill', limit=6)\n",
    "    df = df.fillna(method='bfill', limit=6)\n",
    "    \n",
    "    # Drop remaining\n",
    "    remaining_nulls = df.isna().sum().sum()\n",
    "    if remaining_nulls > 0:\n",
    "        print(f'\\n   Remaining nulls after interpolation: {remaining_nulls}')\n",
    "        df = df.dropna()\n",
    "        print(f'   After dropping: {len(df):,} rows')\n",
    "    else:\n",
    "        print(f'\\n   \u2705 All nulls filled')\n",
    "else:\n",
    "    print('   \u2705 No null values!')\n",
    "\n",
    "print(f'\\nFinal dataset: {len(df):,} rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23bb4c8",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Export Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb8dba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*70)\n",
    "print('\ud83d\udcbe EXPORTING DATASET (1-SECOND RESOLUTION)')\n",
    "print('='*70)\n",
    "\n",
    "# Reorder columns for consistency\n",
    "temporal_cols = ['hour_sin', 'hour_cos', 'dow_sin', 'dow_cos', 'month_sin', 'month_cos']\n",
    "\n",
    "# Define column order\n",
    "appliance_order = ['Aggregate', 'HeatPump', 'Dishwasher', 'WashingMachine', 'Dryer', \n",
    "                   'Oven', 'Stove', 'RangeHood', 'EVCharger', 'EVSocket', \n",
    "                   'GarageCabinet', 'RainwaterPump']\n",
    "\n",
    "# Note: Battery excluded - only present in Nov-Dec 2025 which is outside usable periods\n",
    "energy_flow = ['Solar', 'Grid']\n",
    "\n",
    "# Filter to existing columns\n",
    "appliance_order = [c for c in appliance_order if c in df.columns]\n",
    "energy_flow = [c for c in energy_flow if c in df.columns]\n",
    "\n",
    "final_cols = ['Time'] + appliance_order + energy_flow + temporal_cols\n",
    "df = df[final_cols]\n",
    "\n",
    "print(f'\\nFinal dataset:')\n",
    "print(f'   Rows: {len(df):,}')\n",
    "print(f'   Columns: {len(df.columns)}')\n",
    "print(f'   Resolution: 1 SECOND (native, no resampling)')\n",
    "print(f'   Time range: {df[\"Time\"].min()} \u2192 {df[\"Time\"].max()}')\n",
    "print(f'   Columns: {list(df.columns)}')\n",
    "\n",
    "# Export - using parquet for efficiency with large dataset\n",
    "parquet_path = OUTPUT_DIR / 'nilm_ready_1sec.parquet'\n",
    "df.to_parquet(parquet_path, index=False)\n",
    "\n",
    "print(f'\\n\u2705 Exported:')\n",
    "print(f'   Parquet: {parquet_path}')\n",
    "print(f'   Size: {parquet_path.stat().st_size / 1e9:.2f} GB')\n",
    "\n",
    "# Also save metadata\n",
    "metadata = {\n",
    "    'rows': len(df),\n",
    "    'columns': list(df.columns),\n",
    "    'time_start': str(df['Time'].min()),\n",
    "    'time_end': str(df['Time'].max()),\n",
    "    'resolution': '1 second (native)',\n",
    "    'source': '1sec_new (filtered to usable periods)',\n",
    "    'usable_periods': [\n",
    "        {'period': 'A', 'start': '2024-04-15', 'end': '2024-05-31', 'days': 46},\n",
    "        {'period': 'B', 'start': '2024-07-01', 'end': '2024-09-30', 'days': 92},\n",
    "        {'period': 'C', 'start': '2024-10-09', 'end': '2025-09-30', 'days': 356}\n",
    "    ],\n",
    "    'preprocessing_notes': [\n",
    "        'Applied clip(lower=0) to appliances with sensor offset (dishwasher, washing_machine, stove - small negatives when OFF),',\n",
    "        'Applied clip(lower=0) to all appliances (sensor offset removal, NOT abs())',\n",
    "        'Fixed double counting: garage_cabinet -= ev_charger + ev_socket (aligned with 15-min)',\n",
    "        'Applied noise thresholding: values < 5W \u2192 0 (sensor noise when OFF)',\n",
    "        'Kept negative values for solar, grid, battery (bidirectional energy flow)',\n",
    "        'Battery column excluded (only in Nov-Dec 2025 outside usable periods)',\n",
    "        'EVCharger/EVSocket filled with 0 before Aug 2024',\n",
    "        'Missing columns filled with 0',\n",
    "        'NO RESAMPLING - kept native 1-second resolution for best NILM accuracy',\n",
    "        'Added cyclical temporal features (hour, dow, month sin/cos)',\n",
    "        'Filtered to 3 continuous gap-free periods (494 days total)'\n",
    "    ],\n",
    "    'inverted_ct_columns': ['dishwasher', 'washing_machine', 'stove', 'oven'],\n",
    "    'noise_threshold_kw': 0.005\n",
    "}\n",
    "\n",
    "import json\n",
    "with open(OUTPUT_DIR / 'dataset_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f'   Metadata: {OUTPUT_DIR / \"dataset_metadata.json\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c1e3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print('='*70)\n",
    "print('\ud83d\udcca FINAL SUMMARY')\n",
    "print('='*70)\n",
    "print()\n",
    "print(df.describe().round(4).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6f6e2a",
   "metadata": {},
   "source": [
    "---\n",
    "## \u2705 Dataset Ready for Training\n",
    "\n",
    "### Output Specifications\n",
    "| Aspect | Value |\n",
    "|--------|-------|\n",
    "| **Resolution** | **1 second (native)** |\n",
    "| Total rows | ~40M |\n",
    "| Usable periods | 494 days from 3 continuous periods |\n",
    "| Columns | 20 (Time + Aggregate + 11 appliances + Solar/Grid + 6 temporal) |\n",
    "\n",
    "### Why 1-Second Resolution?\n",
    "According to NILM literature:\n",
    "- **Better accuracy** for short-cycle appliances\n",
    "- **Standard for state-of-the-art** Transformer models (ELECTRIcity, Energformer)\n",
    "- **Preserves transient events** that get smoothed out at 10s\n",
    "\n",
    "### Usable Periods (Gap-Free)\n",
    "| Period | Start | End | Duration |\n",
    "|--------|-------|-----|----------|\n",
    "| A | 2024-04-15 | 2024-05-31 | 46 days |\n",
    "| B | 2024-07-01 | 2024-09-30 | 92 days |\n",
    "| C | 2024-10-09 | 2025-09-30 | 356 days |\n",
    "\n",
    "### Appliances (11)\n",
    "1. HeatPump\n",
    "2. Dishwasher\n",
    "3. WashingMachine\n",
    "4. Dryer\n",
    "5. Oven\n",
    "6. Stove\n",
    "7. RangeHood\n",
    "8. EVCharger (from Aug 2024)\n",
    "9. EVSocket (from Aug 2024)\n",
    "10. GarageCabinet\n",
    "11. RainwaterPump\n",
    "\n",
    "### Recommended Train/Val/Test Split (in Pretraining Notebook)\n",
    "- **Train**: All Period A + Period B + Period C until June 2025 (~14 months)\n",
    "- **Validation**: July - August 2025 (2 months)\n",
    "- **Test**: September 2025 (1 month)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}