{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55365437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Plot settings\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "# Data directory\n",
    "DATA_DIR = Path('..') / '..' / 'data' / 'raw' / '1sec'\n",
    "print(f'Data directory: {DATA_DIR.resolve()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b613fd9",
   "metadata": {},
   "source": [
    "---\n",
    "## 1Ô∏è‚É£ Load and Inventory All Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b82f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all CSV files\n",
    "files = sorted([f for f in os.listdir(DATA_DIR) if f.endswith('.csv')])\n",
    "\n",
    "print('='*80)\n",
    "print('üìÇ FILE INVENTORY')\n",
    "print('='*80)\n",
    "print(f'\\nFound {len(files)} files:\\n')\n",
    "\n",
    "file_info = []\n",
    "for f in files:\n",
    "    path = DATA_DIR / f\n",
    "    # Read first few rows to get info\n",
    "    df_sample = pd.read_csv(path, nrows=5)\n",
    "    # Count rows (fast method)\n",
    "    with open(path, 'r') as file:\n",
    "        row_count = sum(1 for _ in file) - 1  # minus header\n",
    "    \n",
    "    file_info.append({\n",
    "        'file': f,\n",
    "        'rows': row_count,\n",
    "        'columns': len(df_sample.columns)\n",
    "    })\n",
    "    print(f'   üìÑ {f}: {row_count:,} rows, {len(df_sample.columns)} columns')\n",
    "\n",
    "print(f'\\nüìä Total rows across all files: {sum(f[\"rows\"] for f in file_info):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f963775a",
   "metadata": {},
   "source": [
    "---\n",
    "## 2Ô∏è‚É£ Analyze Each File: Building (Aggregate) Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df5fc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*80)\n",
    "print('üîç BUILDING (AGGREGATE) AVAILABILITY PER FILE')\n",
    "print('='*80)\n",
    "print()\n",
    "\n",
    "file_analysis = []\n",
    "\n",
    "for f in files:\n",
    "    path = DATA_DIR / f\n",
    "    df = pd.read_csv(path)\n",
    "    df['_time'] = pd.to_datetime(df['_time'])\n",
    "    \n",
    "    # Time analysis\n",
    "    time_start = df['_time'].min()\n",
    "    time_end = df['_time'].max()\n",
    "    time_range = time_end - time_start\n",
    "    \n",
    "    # Resolution\n",
    "    time_diffs = df['_time'].diff().dt.total_seconds().dropna()\n",
    "    resolution = time_diffs.mode().iloc[0] if len(time_diffs.mode()) > 0 else time_diffs.median()\n",
    "    \n",
    "    # Building analysis\n",
    "    building_null_pct = df['Building'].isna().sum() / len(df) * 100\n",
    "    building_usable = building_null_pct < 50\n",
    "    \n",
    "    # Completeness\n",
    "    expected_rows = time_range.total_seconds() / resolution\n",
    "    completeness = len(df) / expected_rows * 100 if expected_rows > 0 else 0\n",
    "    \n",
    "    file_analysis.append({\n",
    "        'file': f,\n",
    "        'rows': len(df),\n",
    "        'time_start': time_start,\n",
    "        'time_end': time_end,\n",
    "        'days': time_range.days + time_range.seconds/86400,\n",
    "        'resolution_sec': resolution,\n",
    "        'building_null_pct': building_null_pct,\n",
    "        'building_usable': building_usable,\n",
    "        'completeness_pct': completeness\n",
    "    })\n",
    "    \n",
    "    status = '‚úÖ' if building_usable else '‚ùå'\n",
    "    res_str = f'{resolution:.0f}sec'\n",
    "    print(f'{status} {f}')\n",
    "    print(f'   Rows: {len(df):,} | Resolution: {res_str} | Days: {time_range.days}')\n",
    "    print(f'   Building NULL: {building_null_pct:.1f}% | Completeness: {completeness:.1f}%')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c40626d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary table\n",
    "summary_df = pd.DataFrame(file_analysis)\n",
    "summary_df['usable'] = summary_df['building_null_pct'] < 50\n",
    "\n",
    "print('='*80)\n",
    "print('üìä SUMMARY TABLE')\n",
    "print('='*80)\n",
    "print()\n",
    "print(summary_df[['file', 'rows', 'resolution_sec', 'building_null_pct', 'completeness_pct', 'usable']].to_string(index=False))\n",
    "\n",
    "usable_files = summary_df[summary_df['usable']]['file'].tolist()\n",
    "print(f'\\n‚úÖ Usable files: {len(usable_files)}/10')\n",
    "for f in usable_files:\n",
    "    print(f'   ‚Ä¢ {f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f372a36a",
   "metadata": {},
   "source": [
    "---\n",
    "## 3Ô∏è‚É£ Load Usable Files Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb32a859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load only usable files (March, April, May 2024)\n",
    "usable_files = ['samengevoegd_2024-03.csv', 'samengevoegd_2024-04.csv', 'samengevoegd_2024-05.csv']\n",
    "\n",
    "print('='*80)\n",
    "print('üìÇ LOADING USABLE FILES')\n",
    "print('='*80)\n",
    "\n",
    "dfs = []\n",
    "for f in usable_files:\n",
    "    path = DATA_DIR / f\n",
    "    df = pd.read_csv(path)\n",
    "    df['_time'] = pd.to_datetime(df['_time'])\n",
    "    df['source_file'] = f\n",
    "    dfs.append(df)\n",
    "    print(f'   ‚úÖ Loaded {f}: {len(df):,} rows')\n",
    "\n",
    "# Combine\n",
    "df_combined = pd.concat(dfs, ignore_index=True)\n",
    "df_combined = df_combined.sort_values('_time').reset_index(drop=True)\n",
    "\n",
    "print(f'\\nüìä Combined dataset: {len(df_combined):,} rows')\n",
    "print(f'   Time range: {df_combined[\"_time\"].min()} ‚Üí {df_combined[\"_time\"].max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3741284e",
   "metadata": {},
   "source": [
    "---\n",
    "## 4Ô∏è‚É£ Dataset Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1da94b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*80)\n",
    "print('üèóÔ∏è DATASET STRUCTURE')\n",
    "print('='*80)\n",
    "\n",
    "print(f'\\nüìã Columns ({len(df_combined.columns)}):')  \n",
    "for i, col in enumerate(df_combined.columns, 1):\n",
    "    dtype = df_combined[col].dtype\n",
    "    null_pct = df_combined[col].isna().sum() / len(df_combined) * 100\n",
    "    print(f'   {i:2d}. {col:25s} - {str(dtype):15s} (NULL: {null_pct:.1f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52eef210",
   "metadata": {},
   "source": [
    "---\n",
    "## 5Ô∏è‚É£ Numerical Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060f89be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*80)\n",
    "print('üìà NUMERICAL FEATURES ANALYSIS')\n",
    "print('='*80)\n",
    "\n",
    "# Appliance columns (exclude _time and source_file)\n",
    "appliance_cols = [c for c in df_combined.columns if c not in ['_time', 'source_file']]\n",
    "\n",
    "print(f'\\n{\"Column\":<20} {\"Mean\":>10} {\"Std\":>10} {\"Min\":>10} {\"Max\":>10} {\"NULL%\":>8} {\"NEG%\":>8}')\n",
    "print('-' * 80)\n",
    "\n",
    "for col in appliance_cols:\n",
    "    series = df_combined[col]\n",
    "    valid = series.dropna()\n",
    "    \n",
    "    null_pct = series.isna().sum() / len(series) * 100\n",
    "    neg_pct = (valid < 0).sum() / len(valid) * 100 if len(valid) > 0 else 0\n",
    "    \n",
    "    mean_val = valid.mean() if len(valid) > 0 else 0\n",
    "    std_val = valid.std() if len(valid) > 0 else 0\n",
    "    min_val = valid.min() if len(valid) > 0 else 0\n",
    "    max_val = valid.max() if len(valid) > 0 else 0\n",
    "    \n",
    "    print(f'{col:<20} {mean_val:>10.4f} {std_val:>10.4f} {min_val:>10.4f} {max_val:>10.4f} {null_pct:>7.1f}% {neg_pct:>7.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107d1a88",
   "metadata": {},
   "source": [
    "### üí° Key Insights: Negative Values\n",
    "\n",
    "Several appliances show high percentages of negative values:\n",
    "- **Fornuis (Stove)**: ~99% negative - CT sensor offset\n",
    "- **Oven**: ~98% negative - CT sensor offset  \n",
    "- **Vaatwasser (Dishwasher)**: ~92% negative - CT sensor offset\n",
    "- **Wasmachine (Washing Machine)**: ~96% negative - CT sensor offset\n",
    "\n",
    "**Solution**: Apply `clip(lower=0)` during preprocessing (same as 15min pipeline)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d49a38",
   "metadata": {},
   "source": [
    "---\n",
    "## 6Ô∏è‚É£ Resolution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05796377",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*80)\n",
    "print('‚è±Ô∏è RESOLUTION ANALYSIS')\n",
    "print('='*80)\n",
    "\n",
    "for f in usable_files:\n",
    "    df_file = df_combined[df_combined['source_file'] == f].copy()\n",
    "    time_diffs = df_file['_time'].diff().dt.total_seconds().dropna()\n",
    "    \n",
    "    print(f'\\nüìÑ {f}')\n",
    "    print(f'   Median diff: {time_diffs.median():.1f} sec')\n",
    "    print(f'   Mode diff:   {time_diffs.mode().iloc[0]:.1f} sec')\n",
    "    \n",
    "    # Distribution\n",
    "    print(f'   Top 3 intervals:')\n",
    "    for diff, count in time_diffs.value_counts().head(3).items():\n",
    "        pct = count / len(time_diffs) * 100\n",
    "        print(f'      {diff:.0f}sec: {count:,} ({pct:.1f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eefaedd",
   "metadata": {},
   "source": [
    "---\n",
    "## 7Ô∏è‚É£ Ghost Load Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b38e21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*80)\n",
    "print('üëª GHOST LOAD ANALYSIS')\n",
    "print('='*80)\n",
    "\n",
    "# Only where Building is valid\n",
    "df_valid = df_combined[df_combined['Building'].notna()].copy()\n",
    "\n",
    "# Appliance columns (exclude Building, _time, source_file)\n",
    "appliance_only = [c for c in df_valid.columns if c not in ['_time', 'source_file', 'Building']]\n",
    "\n",
    "# Sum of appliances (clip negatives)\n",
    "df_valid['sum_appliances'] = df_valid[appliance_only].clip(lower=0).sum(axis=1)\n",
    "\n",
    "# Ghost load\n",
    "df_valid['ghost_load'] = df_valid['Building'] - df_valid['sum_appliances']\n",
    "\n",
    "building_mean = df_valid['Building'].mean()\n",
    "sum_mean = df_valid['sum_appliances'].mean()\n",
    "ghost_mean = df_valid['ghost_load'].mean()\n",
    "ghost_pct = ghost_mean / building_mean * 100 if building_mean > 0 else 0\n",
    "\n",
    "print(f'\\nüìä Overall Statistics:')\n",
    "print(f'   Building (Aggregate) mean: {building_mean:.4f} kW')\n",
    "print(f'   Sum(Appliances) mean:      {sum_mean:.4f} kW')\n",
    "print(f'   Ghost Load mean:           {ghost_mean:.4f} kW ({ghost_pct:.1f}%)')\n",
    "\n",
    "# Correlation\n",
    "corr = df_valid['Building'].corr(df_valid['sum_appliances'])\n",
    "print(f'\\n   Correlation Building vs Sum: {corr:.4f}')\n",
    "\n",
    "if ghost_pct > 30:\n",
    "    print(f'\\n‚ö†Ô∏è HIGH GHOST LOAD ({ghost_pct:.0f}%): Missing appliances not measured')\n",
    "    print('   Missing in 1sec: Kast garage (~0.27 kW), Laadpaal_stopcontact, Warmtepomp-Sturing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9286851",
   "metadata": {},
   "source": [
    "---\n",
    "## 8Ô∏è‚É£ Visualization: Aggregate vs Sum of Appliances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3424b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample for visualization (too many points otherwise)\n",
    "sample_size = min(10000, len(df_valid))\n",
    "df_sample = df_valid.sample(sample_size, random_state=42).sort_values('_time')\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "# Plot 1: Time series\n",
    "ax1 = axes[0]\n",
    "ax1.plot(df_sample['_time'], df_sample['Building'], alpha=0.7, label='Building (Aggregate)')\n",
    "ax1.plot(df_sample['_time'], df_sample['sum_appliances'], alpha=0.7, label='Sum(Appliances)')\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Power (kW)')\n",
    "ax1.set_title('Building vs Sum of Appliances (Sample)')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Scatter\n",
    "ax2 = axes[1]\n",
    "ax2.scatter(df_sample['sum_appliances'], df_sample['Building'], alpha=0.3, s=5)\n",
    "max_val = max(df_sample['Building'].max(), df_sample['sum_appliances'].max())\n",
    "ax2.plot([0, max_val], [0, max_val], 'r--', label='Perfect match (y=x)')\n",
    "ax2.set_xlabel('Sum of Appliances (kW)')\n",
    "ax2.set_ylabel('Building (kW)')\n",
    "ax2.set_title(f'Correlation: {corr:.3f}')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e426783",
   "metadata": {},
   "source": [
    "---\n",
    "## 9Ô∏è‚É£ Per-Appliance Power Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062dc25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot of appliance power (clipped)\n",
    "appliance_data = df_valid[appliance_only].clip(lower=0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "appliance_data.boxplot(ax=ax, vert=True, showfliers=False)\n",
    "ax.set_xlabel('Appliance')\n",
    "ax.set_ylabel('Power (kW)')\n",
    "ax.set_title('Power Distribution per Appliance (outliers hidden)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46081b2c",
   "metadata": {},
   "source": [
    "---\n",
    "## üîü Temporal Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64b6bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hourly pattern for main appliances\n",
    "df_valid['hour'] = df_valid['_time'].dt.hour\n",
    "\n",
    "# Select top consumers\n",
    "top_appliances = ['Building', 'Warmtepomp', 'Wasmachine', 'Vaatwasser', 'Fornuis']\n",
    "existing_appliances = [a for a in top_appliances if a in df_valid.columns]\n",
    "\n",
    "hourly_mean = df_valid.groupby('hour')[existing_appliances].mean()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "for col in existing_appliances:\n",
    "    if col == 'Building':\n",
    "        ax.plot(hourly_mean.index, hourly_mean[col], linewidth=2, label=col, marker='o')\n",
    "    else:\n",
    "        ax.plot(hourly_mean.index, hourly_mean[col].clip(lower=0), label=col, alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Hour of Day')\n",
    "ax.set_ylabel('Mean Power (kW)')\n",
    "ax.set_title('Average Power Consumption by Hour')\n",
    "ax.legend(bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "ax.set_xticks(range(24))\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd39f6b",
   "metadata": {},
   "source": [
    "---\n",
    "## üìä Summary & Conclusions\n",
    "\n",
    "### ‚úÖ Usable Data\n",
    "| File | Period | Resolution | Rows | Building | Status |\n",
    "|------|--------|------------|------|----------|--------|\n",
    "| 2024-03 | March | 10sec | 154K | 97% valid | ‚úÖ |\n",
    "| 2024-04 | April | 10sec | 219K | 100% valid | ‚úÖ |\n",
    "| 2024-05 | May | 1sec | 1.08M | 100% valid | ‚úÖ |\n",
    "\n",
    "### ‚ùå Unusable Data (June-December)\n",
    "- Building (Aggregate) is 100% NULL\n",
    "- NILM requires Aggregate as input\n",
    "\n",
    "### üîß Preprocessing Steps Needed\n",
    "1. **Resample to 10sec** (unify resolution)\n",
    "2. **Clip negative values** (CT sensor offset)\n",
    "3. **Remove Smappee_laadpaal** (NULL for usable months)\n",
    "4. **Add temporal features** (hour, day of week, month)\n",
    "5. **Export** to NILM-ready format\n",
    "\n",
    "### ‚ö†Ô∏è Limitations\n",
    "- Ghost load ~50% (missing: Kast garage, Laadpaal_stopcontact, Warmtepomp-Sturing)\n",
    "- Only ~80 days of usable data (vs 365 for 15min)\n",
    "- 8 appliances instead of 12"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
