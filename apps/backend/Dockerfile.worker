# =============================================================================
# NILM Backend - Worker Dockerfile
# Runs the Redis inference worker as a standalone service
# =============================================================================

FROM python:3.12-slim-bookworm AS base

ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    PYTHONPATH=/app

WORKDIR /app

# Install system dependencies
RUN apt-get update && \
    apt-get install -y --no-install-recommends curl && \
    rm -rf /var/lib/apt/lists/*

# Create non-root user
RUN groupadd --gid 1000 appgroup && \
    useradd --uid 1000 --gid appgroup --shell /bin/bash --create-home appuser

# =============================================================================
# Production Stage
# =============================================================================
FROM base AS production

# Copy project definition
COPY apps/backend/pyproject.toml ./

# Copy source code
COPY apps/backend/src/ ./src/

# Install the application (and dependencies)
RUN pip install --no-cache-dir torch==2.5.1 --index-url https://download.pytorch.org/whl/cpu && \
    pip install --no-cache-dir .

# Copy models directory
COPY apps/backend/models/ ./models/

# Change ownership to non-root user
RUN chown -R appuser:appgroup /app

# Switch to non-root user
USER appuser

# Run the worker (no $PORT needed - this is not a web service)
CMD ["python", "-m", "app.worker_main"]
